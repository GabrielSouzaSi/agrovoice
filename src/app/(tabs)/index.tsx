import { use, useCallback, useEffect, useMemo, useRef, useState } from "react"
import { View, Text, TouchableOpacity, Alert } from "react-native"
import { useFocusEffect } from "expo-router"
import Vosk from "react-native-vosk"
import * as Speech from "expo-speech"
import { Mic, Square, Trash } from "lucide-react-native"
import {
	useAudioRecorder,
	useAudioPlayer,
	IOSOutputFormat,
	getRecordingPermissionsAsync,
	requestRecordingPermissionsAsync,
	AudioQuality,
} from "expo-audio"
import * as Location from "expo-location"
import { persistFromCache } from "@/lib/fs"
import { colors } from "@/styles/colors"
import { buildRecordingName } from "@/lib/fileName"
import { insertRecorder } from "@/database/recorder"

function normalize(text: string) {
	return String(text || "")
		.toLowerCase()
		.normalize("NFD")
		.replace(/[\u0300-\u036f]/g, "")
		.replace(/[^\p{L}\p{N}\s]/gu, "")
		.replace(/\s+/g, " ")
		.trim()
}
function extractText(res: any) {
	if (typeof res === "string") {
		try {
			const o = JSON.parse(res)
			return o.text ?? o.partial ?? res
		} catch {
			return res
		}
	}
	if (res?.text) return res.text
	if (res?.partial) return res.partial
	return ""
}

// Grammar por tokens (modo comandos)
const COMMAND_GRAMMAR = [
	"abrir",
	"mapa",
	"mostrar",
	"perfil",
	"saldo",
	"meu",
	"voltar",
	"retornar",
	"gravar",
	"voz",
	"o",
	"[unk]",
]

export default function RecordScreen() {
	// fonte din√¢mica para o player (ser√° definida ap√≥s a grava√ß√£o)
	const [source, setSource] = useState<{ uri: string } | null>(null)
	// player vinculado √† fonte acima
	const player = useAudioPlayer(source)
	const vosk = useRef(new Vosk()).current

	const [ready, setReady] = useState(false)
	const [recognizing, setRecognizing] = useState(false)
	const [partial, setPartial] = useState("")
	const [result, setResult] = useState("")
	const [results, setResults] = useState<string[]>([]) // hist√≥rico
	const [lastCommand, setLastCommand] = useState("(nenhum)")
	const [mode, setMode] = useState<"commands" | "dictation">("commands") // <- novo

	const startingRef = useRef(false)
	const commandFiredRef = useRef(false)
	const partialRef = useRef("")

	const recognizingRef = useRef(false)

	// ref para acumular tudo
	const transcriptRef = useRef("")

	// estado de permiss√£o de grava√ß√£o (mic)
	const [perm, setPerm] = useState<"undetermined" | "denied" | "granted">("undetermined")
	useEffect(() => {
		;(async () => {
			// verifica a permiss√£o atual
			const res = await getRecordingPermissionsAsync()
			setPerm(res.status)
			// se n√£o concedida e puder perguntar de novo, solicita ao usu√°rio
			if (res.status !== "granted" && res.canAskAgain) {
				const req = await requestRecordingPermissionsAsync()
				setPerm(req.status)
			}
		})()
	}, [])

	const recorder = useAudioRecorder({
		isMeteringEnabled: true,
		extension: ".m4a",
		sampleRate: 44100,
		numberOfChannels: 1,
		bitRate: 64000,
		android: {
			// enums/strings aceitos pelo expo-audio para Android
			outputFormat: "mpeg4",
			audioEncoder: "aac",
		},
		ios: {
			// enums para iOS (qualidade m√°xima e par√¢metros PCM)
			outputFormat: IOSOutputFormat.MPEG4AAC,
			audioQuality: AudioQuality.MAX,
			linearPCMBitDepth: 16,
			linearPCMIsBigEndian: false,
			linearPCMIsFloat: false,
		},
		web: {
			// fallback para web (quando aplic√°vel)
			mimeType: "audio/webm",
			bitsPerSecond: 128000,
		},
	})

	// Start: "commands" (grammar) ou "dictation" (sem grammar)
	const recognizingStart = useCallback(
		async (startMode: "commands" | "dictation" = "commands") => {
			console.log("recognizingStart =>", ready, recognizingRef.current, startingRef.current)

			if (recognizingRef.current || startingRef.current) return
			//if (!ready) return // s√≥ bloqueia se ainda n√£o carregou pela 1¬™ vez
			startingRef.current = true
			console.log(
				"Modo de grava√ß√£o:",
				startMode === "commands" ? "com grammar" : "sem grammar",
			)

			try {
				// NOVO: grava APENAS no modo ditado "dictation"
				if (startMode === "dictation") {
					transcriptRef.current = "" // üîπ zera transcri√ß√£o acumulada
					setResults([]) // (opcional) limpa hist√≥rico mostrado na tela
					try {
						await recorder.prepareToRecordAsync()
						await recorder.record()
						console.log("Grava√ß√£o iniciada üé§")
					} catch (e) {
						console.warn("Falha ao iniciar grava√ß√£o (dictation):", e)
					}
				}
				commandFiredRef.current = false
				partialRef.current = ""
				setPartial("")
				setResult("")
				setMode(startMode)
				const opts = startMode === "commands" ? { grammar: COMMAND_GRAMMAR } : {}
				const started = await vosk.start(opts as any)
				if (started === undefined) {
					Alert.alert("Voz", "Permiss√£o de microfone negada")
					return
				}
				recognizingRef.current = true // ‚úÖ atualiza ref imediatamente
				setRecognizing(true)
				console.log("Reconhecimento iniciado üé§", startMode)
			} catch (e) {
				console.error("start:", e)
			} finally {
				startingRef.current = false
			}
		},
		[ready, vosk], // ‚¨ÖÔ∏è n√£o dependa de `recognizing` aqui
	)

	const recognizingStop = useCallback(async () => {
		if (!recognizingRef.current) {
			return // j√° est√° parado, n√£o precisa parar de novo
		}
		recognizingRef.current = false
		setRecognizing(false)
		// console.log(mode)
		let { isRecording } = recorder.getStatus()

		try {
			// 2) para o Vosk
			await vosk.stop()
			console.log("Reconhecimento parado ‚èπÔ∏è")

			if (isRecording) {
				await recorder.stop()
				console.log("recognizingStop:" + isRecording)

				// pega todo o texto acumulado
				const transcription = transcriptRef.current

				let filename = buildRecordingName(recorder.uri, "recorder")
				let saved = await persistFromCache(recorder.uri, {
					targetSubdir: "recordings",
					overwrite: false,
					filename,
				})

				let location = await statusGPS()

				console.log(
					"Grava√ß√£o salva!\n" +
						"Name => " +
						saved.name +
						"\nURI => " +
						saved.uri +
						"\nSize => " +
						saved.size,
				)
				let insert = await insertRecorder({
					name: saved.name,
					file: saved.uri,
					transcription: transcription,
					location: location
						? `${location.coords.latitude},${location.coords.longitude}`
						: "Indispon√≠vel",
					datetime: new Date().toISOString(),
				} as any)
				console.log(insert)
				insert
					? Speech.speak("Audio gravado com sucesso")
					: Speech.speak("Erro ao gravar audio")
				// reseta para pr√≥xima vez
				// setSource(saved)
				return
			}
		} catch (e) {
			console.error("stop:", e)
		} finally {
			// 3) atualiza estados/refs
			recognizingRef.current = false // ‚úÖ ref zera j√°
			setRecognizing(false)
			commandFiredRef.current = false
			partialRef.current = ""
			// reseta para pr√≥xima vez
			transcriptRef.current = ""
			setResult("")
			if (isRecording) {
				setTimeout(() => {
					speakCommandVoice()
				}, 5000)
			}
		}
	}, [vosk])

	// A√á√ïES dentro do componente
	const abrirMapa = useCallback(() => {
		Speech.stop()
		Speech.speak("Abrindo mapa", {
			language: "pt-BR",
			onDone: () => {
				// reinicia em modo ditado (sem grammar, timeout maior)
				;(async () => {
					setTimeout(() => {
						recognizingStart("commands")
					}, 5000)
				})()
			},
		})
	}, []) // sem deps de estado
	const mostrarPerfil = useCallback(() => {
		Speech.stop()
		Speech.speak("Mostrando perfil", { language: "pt-BR" })
		console.log(">> mostrarPerfil()")
	}, [])
	const mostrarSaldo = useCallback(() => {
		Speech.stop()
		Speech.speak("Mostrando saldo", { language: "pt-BR" })
		console.log(">> mostrarSaldo()")
	}, [])
	const voltar = useCallback(() => {
		Speech.stop()
		Speech.speak("Voltando", { language: "pt-BR" })
		console.log(">> voltar()")
	}, [])
	// ‚Äúgravar voz‚Äù => trocar para modo ditado na MESMA inst√¢ncia
	const gravarVoz = useCallback(async () => {
		Speech.stop()
		Speech.speak("Gravar voz", {
			language: "pt-BR",
			onDone: () => {
				// reinicia em modo ditado (sem grammar, timeout maior)
				;(async () => {
					await recognizingStop()
					await recognizingStart("dictation")
				})()
			},
		})
	}, [recognizingStop, recognizingStart]) // sem deps de estado

	// Padr√µes de comando
	const COMMANDS = useMemo(
		() => [
			{ label: "abrir mapa", re: /(^|\s)abrir\s+(o\s+)?mapa(\s|$)/, run: abrirMapa },
			{
				label: "mostrar perfil",
				re: /(^|\s)(mostrar\s+(o\s+)?)?perfil(\s|$)/,
				run: mostrarPerfil,
			},
			{ label: "saldo", re: /(^|\s)(meu\s+)?saldo(\s|$)/, run: mostrarSaldo },
			{ label: "voltar", re: /(^|\s)(voltar|retornar)(\s|$)/, run: voltar },
			{ label: "gravar voz", re: /(^|\s)gravar\s+voz(\s|$)/, run: gravarVoz },
		],
		[abrirMapa, mostrarPerfil, mostrarSaldo, voltar, gravarVoz],
	)

	// Carrega modelo 1x
	useEffect(() => {
		vosk.loadModel("vosk-model-pt")
			.then(() => setReady(true))
			.catch((e) => console.error("loadModel:", e))
		return () => {
			vosk.unload()
		}
	}, [vosk])

	// Dispara 1 comando por ciclo
	const tryRunCommand = useCallback(
		async (raw: string) => {
			if (commandFiredRef.current) return
			const t = normalize(raw)
			if (!t) return
			//console.log("[tryRunCommand] texto:", t)
			for (const c of COMMANDS) {
				if (c.re.test(t)) {
					commandFiredRef.current = true
					setLastCommand(c.label)
					//console.log("[tryRunCommand] comando reconhecido:", c.label)
					try {
						await Promise.resolve(c.run())
					} catch (e) {
						console.error("Falha ao executar a√ß√£o:", e)
					} finally {
						// se comando N√ÉO foi ‚Äúgravar voz‚Äù, pare ap√≥s executar
						if (c.label !== "gravar voz") recognizingStop()
					}
					break
				}
			}
		},
		[COMMANDS],
	)

	const speakCommandVoice = useCallback(async () => {
		Speech.stop()
		Speech.speak("Diga um comando", {
			language: "pt-BR",
			onDone: () => {
				;(async () => {
					await recognizingStart("commands")
				})()
			},
		})
	}, [])

	// Listeners
	useEffect(() => {
		// üîπ helper local para detectar "stop" no modo ditado
		const handleHotwordStop = (text: string) => {
			const n = normalize(text)
			if (mode === "dictation" && /\bfinalizar\b/i.test(n)) {
				// limpa UI de parcial e encerra
				partialRef.current = ""
				setPartial("")
				recognizingStop()
				return true
			}
			return false
		}
		const onResult = vosk.onResult((res: string) => {
			const t = extractText(res)
			if (!t) return

			if (mode === "dictation") {
				transcriptRef.current = (transcriptRef.current + " " + t).trim() // üîπ acumula
				setResults((prev) => [...prev, t]) // (UI) hist√≥rico
				// ‚õî HOTWORD
				if (handleHotwordStop(t)) return
			}
		})

		const onPartial = vosk.onPartialResult((s: string) => {
			const raw = extractText(s)

			partialRef.current = raw
			setPartial(raw)
			// responder j√° em parcial (mais responsivo) S√ì no modo comandos
			if (mode === "commands") tryRunCommand(raw)
		})
		const onFinal = vosk.onFinalResult((res: string) => {
			const t = extractText(res)
			partialRef.current = ""
			setPartial("")

			if (!t) return

			if (mode === "dictation") {
				transcriptRef.current = (transcriptRef.current + " " + t).trim() // üîπ acumula
				setResults((prev) => [...prev, t]) // (UI)
				// ‚õî HOTWORD
				if (handleHotwordStop(t)) return
			} else {
				tryRunCommand(normalize(t))
			}
		})
		const onError = vosk.onError((e: any) => console.error("Vosk error:", e))
		const onTimeout = vosk.onTimeout(async () => {
			console.log("[timeout] √∫ltimo parcial:", partialRef.current)
			if (mode === "commands" && partialRef.current && !commandFiredRef.current) {
				await tryRunCommand(partialRef.current)
			}
			console.log("[timeout] parando reconhecimento")
			recognizingStop()
		})
		return () => {
			onResult.remove()
			onPartial.remove()
			onFinal.remove()
			onError.remove()
			onTimeout.remove()
		}
	}, [vosk, tryRunCommand, mode])

	// Para ao desfocar
	useFocusEffect(
		useCallback(() => {
			return () => {
				recognizingStop()
			}
		}, []),
	)

	useEffect(() => {
		recognizingRef.current = recognizing
	}, [recognizing])

	const clearText = () => {
		setPartial("")
		setResult("")
		setLastCommand("(nenhum)")
	}

	useEffect(() => {
		if (results.length > 0) console.log(results.join(" "))
	}, [results])

	// Solicitar permiss√£o
	async function getPermissionGPS() {
		const { status } = await Location.requestForegroundPermissionsAsync()

		if (status !== "granted") {
			Alert.alert("Permiss√£o negada", "D√™ permiss√£o da localiza√ß√£o para continuar.", [
				{ text: "OK", onPress: () => getPermissionGPS() },
			])
			return
		} else {
			await statusGPS()
		}
	}
	// Verificar se o GPS est√° ativado
	async function statusGPS() {
		const isGPSEnabled = await Location.hasServicesEnabledAsync()

		if (!isGPSEnabled) {
			Alert.alert("GPS desativado", "Ative o GPS para capturar a localiza√ß√£o.")
			return false
		} else {
			// Capturar localiza√ß√£o
			const userLocation = await Location.getCurrentPositionAsync({
				accuracy: Location.Accuracy.High,
			})
			// Armazena a localiza√ß√£o no estado
			return userLocation
		}
	}

	useEffect(() => {
		getPermissionGPS()
	}, [])

	return (
		<View className="flex-1 justify-center items-center bg-gray-1000 gap-3 p-4">
			{/* {source?.uri && <Button title="play" onPress={() => player.play()} />} */}
			<View className="absolute top-24 p-4 rounded-lg bg-gray-900">
				<Text className="text-white-500 text-lg font-semiBold">
					{recognizing
						? mode === "commands"
							? "Escutando comando..."
							: "Gravando voz..."
						: "Pressione o bot√£o e fale um comando"}
				</Text>
			</View>

			<View className="absolute top-44 p-4 rounded-lg bg-gray-900 w-11/12">
				{!!partial && (
					<Text className="text-gray-500 text-sm font-semiBold italic">
						Escutando: {partial}
					</Text>
				)}
				<Text className="text-gray-500 text-sm font-semiBold italic mt-2">
					√öltimo comando: {lastCommand}
				</Text>
			</View>

			<View className="items-center justify-center">
				<TouchableOpacity
					className={`w-20 h-20 rounded-full bg-green-500 items-center justify-center shadow-lg shadow-black-500/50 elevation-md ${recognizing ? "bg-red-500" : ""}`}
					disabled={!ready || startingRef.current}
					onPress={() => (recognizing ? recognizingStop() : speakCommandVoice())}
				>
					{recognizing ? (
						<Square size={32} color="#fff" />
					) : (
						<Mic size={32} color="#fff" />
					)}
				</TouchableOpacity>
			</View>

			{recognizing && (
				<TouchableOpacity
					className="absolute bottom-10 p-4 rounded-lg bg-gray-900"
					onPress={clearText}
				>
					<Trash size={24} color={colors.red[500]} />
				</TouchableOpacity>
			)}
		</View>
	)
}
